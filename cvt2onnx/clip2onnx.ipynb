{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b21ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U torch\n",
    "!pip install -U clip\n",
    "!pip install -U open_clip_torch\n",
    "!pip install -U onnx\n",
    "!pip install -U onnxsim\n",
    "!pip install -U onnxscript\n",
    "!pip uninstall -y onnxruntime\n",
    "!pip uninstall -y onnxruntime-gpu\n",
    "!pip install -U onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !wget https://huggingface.co/laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K/resolve/main/open_clip_pytorch_model.bin?download=true\n",
    "# !wget https://huggingface.co/laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K/resolve/main/open_clip_pytorch_model.bin?download=true\n",
    "# # rename it back\n",
    "# !mv open_clip_pytorch_model.bin?download=true open_clip_pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30d8257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "# check gpu\n",
    "# print(\"ONNX Runtime version:\", ort.__version__)\n",
    "print(\"Available providers:\", ort.get_available_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332ad254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import open_clip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# onnx cannot export with cuda\n",
    "# model, preprocess = clip.load(\"CLIP-ViT-L-14-DataComp.XL-s13B-b90K/open_clip_pytorch_model.bin\", device=\"cpu\", jit=False)\n",
    "model_name = \"ViT-L-14\"\n",
    "print(open_clip.list_pretrained(model_name))\n",
    "\n",
    "pretrained = \"/home/haoyu/projects/model2onnx/open_clip_pytorch_model.bin\"\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    model_name=model_name,\n",
    "    pretrained=pretrained,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ffee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess(Image.open(\"/home/haoyu/projects/model2onnx/cat.jpg\")).unsqueeze(0).cpu() # [1, 3, 224, 224]\n",
    "image_onnx = image.detach().cpu().numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f149c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from onnxsim import simplify\n",
    "\n",
    "dummy_input_shape = (4, 3, 224, 224)\n",
    "dummy_input = torch.randn(dummy_input_shape, dtype=torch.float32)\n",
    "onnx_path = \"clip_model_raw.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    model.visual,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    opset_version=18,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "print(f\"Exported raw model to {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(onnx_path)\n",
    "model_simplified, check = simplify(onnx_model)\n",
    "print(model_simplified.graph.input[0])\n",
    "print(model_simplified.graph.output[0])\n",
    "\n",
    "if check:\n",
    "    onnx_simplified_path = \"clip_model_simplified.onnx\"\n",
    "    onnx.save(model_simplified, onnx_simplified_path)\n",
    "    print(f\"Simplified model saved to {onnx_simplified_path}\")\n",
    "else:\n",
    "    print(\"⚠️ Simplified model could not be validated — check graph manually.\")\n",
    "\n",
    "\n",
    "session = ort.InferenceSession(onnx_simplified_path)\n",
    "inputs = {session.get_inputs()[0].name: np.random.randn(*dummy_input_shape).astype(np.float32)}\n",
    "outputs = session.run(None, inputs)\n",
    "print(\"Inference success, output shape:\", [o.shape for o in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_simplified_path = \"clip_model_simplified.onnx\"\n",
    "onnx_model = onnx.load(onnx_simplified_path)\n",
    "\n",
    "# Check input shape\n",
    "input_shape = onnx_model.graph.input[0].type.tensor_type.shape\n",
    "print(\"Input shape:\", input_shape)\n",
    "\n",
    "# Check output shape\n",
    "output_shape = onnx_model.graph.output[0].type.tensor_type.shape\n",
    "print(\"Output shape:\", output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6607ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess(Image.open(\"/home/haoyu/projects/model2onnx/cat.jpg\")).unsqueeze(0).cpu() # [1, 3, 224, 224]\n",
    "image_onnx = image.detach().cpu().numpy().astype(np.float32)\n",
    "print(\"Input image shape for ONNX model:\", image_onnx.shape)\n",
    "\n",
    "ori_output = None\n",
    "onnx_output_np = None\n",
    "\n",
    "# check original model output as numPy\n",
    "with torch.no_grad():\n",
    "    original_output = model.encode_image(torch.from_numpy(image_onnx))\n",
    "    original_output_np = original_output.cpu().numpy()\n",
    "    print(\"Original model output shape:\", original_output_np.shape)\n",
    "    ori_output = original_output_np[0]\n",
    "\n",
    "# output of simplified ONNX model matches original model output\n",
    "onnx_simplified_path = \"clip_model_simplified.onnx\"\n",
    "simplified_model = ort.InferenceSession(onnx_simplified_path)\n",
    "inputs = {simplified_model.get_inputs()[0].name: image_onnx}\n",
    "onnx_outputs = simplified_model.run(None, inputs)\n",
    "onnx_output_np = onnx_outputs[0]\n",
    "\n",
    "print(\"ONNX model output shape:\", ori_output.shape)\n",
    "print(\"simplified_model shape:\", onnx_output_np[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9838bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_diff = np.abs(ori_output - onnx_output_np[0])\n",
    "mean_diff = np.mean(abs_diff)\n",
    "print(\"Mean absolute difference between original and ONNX output:\", mean_diff)\n",
    "\n",
    "is_close = np.all(mean_diff < 1e-5)\n",
    "print(\"Outputs are almost identical:\", is_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "# test onnx inference with batch size 1 speed\n",
    "dummy_input_shape = (6, 3, 224, 224)\n",
    "onnx_simplified_path = \"clip-visual.onnx\"\n",
    "# Average inference time over 100 runs with batch size 6: 4.10 ms\n",
    "dummy_input_shape = (4, 3, 224, 224)\n",
    "onnx_simplified_path = \"clip_model_raw.onnx\"\n",
    "# Average inference time over 100 runs with batch size 4: 39.69 ms\n",
    "\n",
    "session = ort.InferenceSession(onnx_simplified_path)\n",
    "# set GPU execution provider if available\n",
    "if 'CUDAExecutionProvider' in onnxruntime.get_available_providers():\n",
    "    session.set_providers(['CUDAExecutionProvider'])\n",
    "\n",
    "inputs = {session.get_inputs()[0].name: np.random.randn(*dummy_input_shape).astype(np.float32)}\n",
    "from time import perf_counter\n",
    "\n",
    "# warm up for 50 runs\n",
    "for _ in range(50):\n",
    "    _ = session.run(None, inputs)\n",
    "\n",
    "# mean 100 runs with random input\n",
    "num_runs = 100\n",
    "start_time = perf_counter()\n",
    "for _ in range(num_runs):\n",
    "    _ = session.run(None, inputs)\n",
    "end_time = perf_counter()\n",
    "avg_time = (end_time - start_time) / num_runs\n",
    "print(f\"Average inference time over {num_runs} runs with batch size {dummy_input_shape[0]}: {avg_time * 1000:.2f} ms\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
