{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "readme_example.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noahzhy/model2onnx/blob/main/examples/readme_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Restart colab session after installation\n",
        "Reload the session if something doesn't work"
      ],
      "metadata": {
        "id": "whlsBiJgR8le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install git+https://github.com/Lednik7/CLIP-ONNX.git\n",
        "!pip3 install git+https://github.com/openai/CLIP.git\n",
        "!pip3 install onnxruntime-gpu"
      ],
      "metadata": {
        "id": "HnbpAkvuR73L",
        "outputId": "0cd7e1ef-6497-476a-d6d5-ae2d9199857d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Lednik7/CLIP-ONNX.git\n",
            "  Cloning https://github.com/Lednik7/CLIP-ONNX.git to /tmp/pip-req-build-za525wbb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Lednik7/CLIP-ONNX.git /tmp/pip-req-build-za525wbb\n",
            "  Resolved https://github.com/Lednik7/CLIP-ONNX.git to commit ebd4852b7d3ebf116709abf33b26832acaba947b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of clip-onnx to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.1 (from clip-onnx) (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-hnm6ihky\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-hnm6ihky\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (25.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (0.23.0+cu126)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->clip==1.0) (0.2.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->clip==1.0) (3.0.3)\n",
            "Requirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.12/dist-packages (1.23.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (25.9.23)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (1.13.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Dz0ADojHz8hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget -c -O CLIP.png https://github.com/openai/CLIP/blob/main/CLIP.png?raw=true"
      ],
      "metadata": {
        "id": "tqy0zKM4R-7M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi # CPU Provider"
      ],
      "metadata": {
        "id": "eKqETHL4YscZ",
        "outputId": "946afea6-aecd-42ca-e020-215a938e8233",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "\n",
        "print(onnxruntime.get_device()) # priority device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8IN72OnSAIh",
        "outputId": "b5037b3b-141b-47d1-a4fe-037884ddd083"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CPU inference mode"
      ],
      "metadata": {
        "id": "U1Pr-YTtSEhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "gZTxanR26knr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open_clip_torch"
      ],
      "metadata": {
        "id": "9HPpG8aswmsU",
        "outputId": "2c4eddf4-da21-4b24-a0ec-740e2cb8ab8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.23.0+cu126)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (2024.11.6)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (6.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.6.2)\n",
            "Requirement already satisfied: timm>=1.0.17 in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (1.0.20)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm>=1.0.17->open_clip_torch) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->open_clip_torch) (0.2.14)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->open_clip_torch) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->open_clip_torch) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->open_clip_torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->open_clip_torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (2025.10.5)\n",
            "Downloading open_clip_torch-3.2.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: open_clip_torch\n",
            "Successfully installed open_clip_torch-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K/resolve/main/open_clip_pytorch_model.bin?download=true"
      ],
      "metadata": {
        "id": "WVL32v_xy381",
        "outputId": "c66d50ea-d7fc-4b5d-b08a-a138f4479199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-29 11:47:54--  https://huggingface.co/laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K/resolve/main/open_clip_pytorch_model.bin?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 3.170.185.25, 3.170.185.14, 3.170.185.33, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.170.185.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/6448813e058f3572dd1df3d6/77f47423fe8ee22ed9615cf122e3ca65ae89ad96aaed01b99d5f8b0c4d09dd20?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251029%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251029T114754Z&X-Amz-Expires=3600&X-Amz-Signature=182d06e5f3e9e27f0e5fe22f2d5440b42280071a6388660aa7d5d2b4100745a4&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27open_clip_pytorch_model.bin%3B+filename%3D%22open_clip_pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&x-id=GetObject&Expires=1761742074&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2MTc0MjA3NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NDQ4ODEzZTA1OGYzNTcyZGQxZGYzZDYvNzdmNDc0MjNmZThlZTIyZWQ5NjE1Y2YxMjJlM2NhNjVhZTg5YWQ5NmFhZWQwMWI5OWQ1ZjhiMGM0ZDA5ZGQyMCoifV19&Signature=urjejpria5hCJL8p34AHsfxACN1ewRT1-Bh7ixXv%7EA7cDZ6mMX2WFu7cPHAidGTRn7wC1MxfwcC4JLqkEMHnDTCKO1ixk1nhlBR7K09E8g9eD6-jQ2JLKGX6tv2q2ego68emcgym3nQ1fNqtoEB0tBlYl9IZj3zNq1MKEE9rFfnIHyP-mQxCboudSRz-KSCg6eLx4n5gbFkrljSwXGSewwHiEQlFtxJmHFlL2NZ%7EhOotnHJ9W05jvBlZoQeICv6vcYZ4q50ia7QdWKFzIjRQEZFIi%7E2xIZ2zzp35RKhHFkpjBrCHJ2z8tE1Y1rQAduoEDWH-sz8G4-PX18JyY9ImNw__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-10-29 11:47:54--  https://cas-bridge.xethub.hf.co/xet-bridge-us/6448813e058f3572dd1df3d6/77f47423fe8ee22ed9615cf122e3ca65ae89ad96aaed01b99d5f8b0c4d09dd20?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251029%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251029T114754Z&X-Amz-Expires=3600&X-Amz-Signature=182d06e5f3e9e27f0e5fe22f2d5440b42280071a6388660aa7d5d2b4100745a4&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27open_clip_pytorch_model.bin%3B+filename%3D%22open_clip_pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&x-id=GetObject&Expires=1761742074&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2MTc0MjA3NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NDQ4ODEzZTA1OGYzNTcyZGQxZGYzZDYvNzdmNDc0MjNmZThlZTIyZWQ5NjE1Y2YxMjJlM2NhNjVhZTg5YWQ5NmFhZWQwMWI5OWQ1ZjhiMGM0ZDA5ZGQyMCoifV19&Signature=urjejpria5hCJL8p34AHsfxACN1ewRT1-Bh7ixXv%7EA7cDZ6mMX2WFu7cPHAidGTRn7wC1MxfwcC4JLqkEMHnDTCKO1ixk1nhlBR7K09E8g9eD6-jQ2JLKGX6tv2q2ego68emcgym3nQ1fNqtoEB0tBlYl9IZj3zNq1MKEE9rFfnIHyP-mQxCboudSRz-KSCg6eLx4n5gbFkrljSwXGSewwHiEQlFtxJmHFlL2NZ%7EhOotnHJ9W05jvBlZoQeICv6vcYZ4q50ia7QdWKFzIjRQEZFIi%7E2xIZ2zzp35RKhHFkpjBrCHJ2z8tE1Y1rQAduoEDWH-sz8G4-PX18JyY9ImNw__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.160.213.16, 18.160.213.34, 18.160.213.84, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.160.213.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1710639109 (1.6G) [application/octet-stream]\n",
            "Saving to: ‘open_clip_pytorch_model.bin?download=true’\n",
            "\n",
            "open_clip_pytorch_m 100%[===================>]   1.59G   133MB/s    in 15s     \n",
            "\n",
            "2025-10-29 11:48:09 (112 MB/s) - ‘open_clip_pytorch_model.bin?download=true’ saved [1710639109/1710639109]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import clip\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import open_clip\n",
        "\n",
        "# onnx cannot export with cuda\n",
        "# model, preprocess = clip.load(\"CLIP-ViT-L-14-DataComp.XL-s13B-b90K/open_clip_pytorch_model.bin\", device=\"cpu\", jit=False)\n",
        "model_name = \"ViT-L-14\"\n",
        "#print(open_clip.list_models())\n",
        "print(open_clip.list_pretrained(model_name))\n",
        "\n",
        "#pretrained = os.path.join(model_dir, f\"eva02_large_patch14_clip_224.merged2b_s4b_b131k/open_clip_pytorch_model.bin\")\n",
        "\n",
        "pretrained = \"/content/open_clip_pytorch_model.bin\"\n",
        "model, _, preprocess = open_clip.create_model_and_transforms(\n",
        "    model_name=model_name,\n",
        "    pretrained=pretrained,\n",
        ")\n",
        "\n",
        "# batch first\n",
        "image = preprocess(Image.open(\"CLIP.png\")).unsqueeze(0).cpu() # [1, 3, 224, 224]\n",
        "image_onnx = image.detach().cpu().numpy().astype(np.float32)\n",
        "\n",
        "# batch first\n",
        "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).cpu() # [3, 77]\n",
        "text_onnx = text.detach().cpu().numpy().astype(np.int32)"
      ],
      "metadata": {
        "id": "rPwc6A2SSGyl",
        "outputId": "774c6e80-07c9-4f00-9a0e-1f467d9ed514",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['RN50:openai', 'RN50:yfcc15m', 'RN50:cc12m', 'RN101:openai', 'RN101:yfcc15m', 'RN50x4:openai', 'RN50x16:openai', 'RN50x64:openai', 'ViT-B-32:openai', 'ViT-B-32:laion400m_e31', 'ViT-B-32:laion400m_e32', 'ViT-B-32:laion2b_e16', 'ViT-B-32:laion2b_s34b_b79k', 'ViT-B-32:datacomp_xl_s13b_b90k', 'ViT-B-32:datacomp_m_s128m_b4k', 'ViT-B-32:commonpool_m_clip_s128m_b4k', 'ViT-B-32:commonpool_m_laion_s128m_b4k', 'ViT-B-32:commonpool_m_image_s128m_b4k', 'ViT-B-32:commonpool_m_text_s128m_b4k', 'ViT-B-32:commonpool_m_basic_s128m_b4k', 'ViT-B-32:commonpool_m_s128m_b4k', 'ViT-B-32:datacomp_s_s13m_b4k', 'ViT-B-32:commonpool_s_clip_s13m_b4k', 'ViT-B-32:commonpool_s_laion_s13m_b4k', 'ViT-B-32:commonpool_s_image_s13m_b4k', 'ViT-B-32:commonpool_s_text_s13m_b4k', 'ViT-B-32:commonpool_s_basic_s13m_b4k', 'ViT-B-32:commonpool_s_s13m_b4k', 'ViT-B-32:metaclip_400m', 'ViT-B-32:metaclip_fullcc', 'ViT-B-32-256:datacomp_s34b_b86k', 'ViT-B-16:openai', 'ViT-B-16:laion400m_e31', 'ViT-B-16:laion400m_e32', 'ViT-B-16:laion2b_s34b_b88k', 'ViT-B-16:datacomp_xl_s13b_b90k', 'ViT-B-16:datacomp_l_s1b_b8k', 'ViT-B-16:commonpool_l_clip_s1b_b8k', 'ViT-B-16:commonpool_l_laion_s1b_b8k', 'ViT-B-16:commonpool_l_image_s1b_b8k', 'ViT-B-16:commonpool_l_text_s1b_b8k', 'ViT-B-16:commonpool_l_basic_s1b_b8k', 'ViT-B-16:commonpool_l_s1b_b8k', 'ViT-B-16:dfn2b', 'ViT-B-16:metaclip_400m', 'ViT-B-16:metaclip_fullcc', 'ViT-B-16-plus-240:laion400m_e31', 'ViT-B-16-plus-240:laion400m_e32', 'ViT-L-14:openai', 'ViT-L-14:laion400m_e31', 'ViT-L-14:laion400m_e32', 'ViT-L-14:laion2b_s32b_b82k', 'ViT-L-14:datacomp_xl_s13b_b90k', 'ViT-L-14:commonpool_xl_clip_s13b_b90k', 'ViT-L-14:commonpool_xl_laion_s13b_b90k', 'ViT-L-14:commonpool_xl_s13b_b90k', 'ViT-L-14:metaclip_400m', 'ViT-L-14:metaclip_fullcc', 'ViT-L-14:dfn2b', 'ViT-L-14:dfn2b_s39b', 'ViT-L-14-336:openai', 'ViT-H-14:laion2b_s32b_b79k', 'ViT-H-14:metaclip_fullcc', 'ViT-H-14:metaclip_altogether', 'ViT-H-14:dfn5b', 'ViT-H-14-378:dfn5b', 'ViT-g-14:laion2b_s12b_b42k', 'ViT-g-14:laion2b_s34b_b88k', 'ViT-bigG-14:laion2b_s39b_b160k', 'ViT-bigG-14:metaclip_fullcc', 'roberta-ViT-B-32:laion2b_s12b_b32k', 'xlm-roberta-base-ViT-B-32:laion5b_s13b_b90k', 'xlm-roberta-large-ViT-H-14:frozen_laion5b_s13b_b90k', 'convnext_base:laion400m_s13b_b51k', 'convnext_base_w:laion2b_s13b_b82k', 'convnext_base_w:laion2b_s13b_b82k_augreg', 'convnext_base_w:laion_aesthetic_s13b_b82k', 'convnext_base_w_320:laion_aesthetic_s13b_b82k', 'convnext_base_w_320:laion_aesthetic_s13b_b82k_augreg', 'convnext_large_d:laion2b_s26b_b102k_augreg', 'convnext_large_d_320:laion2b_s29b_b131k_ft', 'convnext_large_d_320:laion2b_s29b_b131k_ft_soup', 'convnext_xxlarge:laion2b_s34b_b82k_augreg', 'convnext_xxlarge:laion2b_s34b_b82k_augreg_rewind', 'convnext_xxlarge:laion2b_s34b_b82k_augreg_soup', 'coca_ViT-B-32:laion2b_s13b_b90k', 'coca_ViT-B-32:mscoco_finetuned_laion2b_s13b_b90k', 'coca_ViT-L-14:laion2b_s13b_b90k', 'coca_ViT-L-14:mscoco_finetuned_laion2b_s13b_b90k', 'EVA01-g-14:laion400m_s11b_b41k', 'EVA01-g-14-plus:merged2b_s11b_b114k', 'EVA02-B-16:merged2b_s8b_b131k', 'EVA02-L-14:merged2b_s4b_b131k', 'EVA02-L-14-336:merged2b_s6b_b61k', 'EVA02-E-14:laion2b_s4b_b115k', 'EVA02-E-14-plus:laion2b_s9b_b144k', 'ViT-B-16-SigLIP:webli', 'ViT-B-16-SigLIP-256:webli', 'ViT-B-16-SigLIP-i18n-256:webli', 'ViT-B-16-SigLIP-384:webli', 'ViT-B-16-SigLIP-512:webli', 'ViT-L-16-SigLIP-256:webli', 'ViT-L-16-SigLIP-384:webli', 'ViT-SO400M-14-SigLIP:webli', 'ViT-SO400M-16-SigLIP-i18n-256:webli', 'ViT-SO400M-14-SigLIP-378:webli', 'ViT-SO400M-14-SigLIP-384:webli', 'ViT-B-32-SigLIP2-256:webli', 'ViT-B-16-SigLIP2:webli', 'ViT-B-16-SigLIP2-256:webli', 'ViT-B-16-SigLIP2-384:webli', 'ViT-B-16-SigLIP2-512:webli', 'ViT-L-16-SigLIP2-256:webli', 'ViT-L-16-SigLIP2-384:webli', 'ViT-L-16-SigLIP2-512:webli', 'ViT-SO400M-14-SigLIP2:webli', 'ViT-SO400M-14-SigLIP2-378:webli', 'ViT-SO400M-16-SigLIP2-256:webli', 'ViT-SO400M-16-SigLIP2-384:webli', 'ViT-SO400M-16-SigLIP2-512:webli', 'ViT-gopt-16-SigLIP2-256:webli', 'ViT-gopt-16-SigLIP2-384:webli', 'ViT-L-14-CLIPA:datacomp1b', 'ViT-L-14-CLIPA-336:datacomp1b', 'ViT-H-14-CLIPA:datacomp1b', 'ViT-H-14-CLIPA-336:laion2b', 'ViT-H-14-CLIPA-336:datacomp1b', 'ViT-bigG-14-CLIPA:datacomp1b', 'ViT-bigG-14-CLIPA-336:datacomp1b', 'nllb-clip-base:v1', 'nllb-clip-large:v1', 'nllb-clip-base-siglip:v1', 'nllb-clip-base-siglip:mrl', 'nllb-clip-large-siglip:v1', 'nllb-clip-large-siglip:mrl', 'MobileCLIP-S1:datacompdr', 'MobileCLIP-S2:datacompdr', 'MobileCLIP-B:datacompdr', 'MobileCLIP-B:datacompdr_lt', 'MobileCLIP2-B:dfndr2b', 'MobileCLIP2-S0:dfndr2b', 'MobileCLIP2-S2:dfndr2b', 'MobileCLIP2-S3:dfndr2b', 'MobileCLIP2-S4:dfndr2b', 'MobileCLIP2-L-14:dfndr2b', 'ViTamin-S:datacomp1b', 'ViTamin-S-LTT:datacomp1b', 'ViTamin-B:datacomp1b', 'ViTamin-B-LTT:datacomp1b', 'ViTamin-L:datacomp1b', 'ViTamin-L-256:datacomp1b', 'ViTamin-L-336:datacomp1b', 'ViTamin-L-384:datacomp1b', 'ViTamin-L2:datacomp1b', 'ViTamin-L2-256:datacomp1b', 'ViTamin-L2-336:datacomp1b', 'ViTamin-L2-384:datacomp1b', 'ViTamin-XL-256:datacomp1b', 'ViTamin-XL-336:datacomp1b', 'ViTamin-XL-384:datacomp1b', 'PE-Core-T-16-384:meta', 'PE-Core-S-16-384:meta', 'PE-Core-B-16:meta', 'PE-Core-L-14-336:meta', 'PE-Core-bigG-14-448:meta', 'ViT-H-14-worldwide:metaclip2_worldwide', 'ViT-H-14-worldwide-378:metaclip2_worldwide', 'ViT-bigG-14-worldwide:metaclip2_worldwide', 'ViT-bigG-14-worldwide-378:metaclip2_worldwide', 'RN50-quickgelu:openai', 'RN50-quickgelu:yfcc15m', 'RN50-quickgelu:cc12m', 'RN101-quickgelu:openai', 'RN101-quickgelu:yfcc15m', 'RN50x4-quickgelu:openai', 'RN50x16-quickgelu:openai', 'RN50x64-quickgelu:openai', 'ViT-B-32-quickgelu:openai', 'ViT-B-32-quickgelu:laion400m_e31', 'ViT-B-32-quickgelu:laion400m_e32', 'ViT-B-32-quickgelu:metaclip_400m', 'ViT-B-32-quickgelu:metaclip_fullcc', 'ViT-B-16-quickgelu:openai', 'ViT-B-16-quickgelu:dfn2b', 'ViT-B-16-quickgelu:metaclip_400m', 'ViT-B-16-quickgelu:metaclip_fullcc', 'ViT-L-14-quickgelu:openai', 'ViT-L-14-quickgelu:metaclip_400m', 'ViT-L-14-quickgelu:metaclip_fullcc', 'ViT-L-14-quickgelu:dfn2b', 'ViT-L-14-336-quickgelu:openai', 'ViT-H-14-quickgelu:metaclip_fullcc', 'ViT-H-14-quickgelu:dfn5b', 'ViT-H-14-378-quickgelu:dfn5b', 'ViT-bigG-14-quickgelu:metaclip_fullcc', 'ViT-H-14-worldwide-quickgelu:metaclip2_worldwide']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import clip_onnx\n",
        "from clip_onnx import clip_onnx, attention\n",
        "# clip.model.ResidualAttentionBlock.attention = attention\n",
        "\n",
        "visual_path = \"clip_visual.onnx\"\n",
        "textual_path = \"clip_textual.onnx\"\n",
        "\n",
        "onnx_model = clip_onnx(model, visual_path=visual_path, textual_path=textual_path)\n",
        "onnx_model.convert2onnx(image, text, verbose=True)\n",
        "# ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
        "onnx_model.start_sessions(providers=[\"CPUExecutionProvider\"]) # cpu mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "oYM5FDSGSJBW",
        "outputId": "84b2fdf9-9322-43e3-8392-1f8e1301d973"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'clip_onnx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-44713449.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mclip_onnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mclip_onnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclip_onnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# clip.model.ResidualAttentionBlock.attention = attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvisual_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"clip_visual.onnx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'clip_onnx'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_features = onnx_model.encode_image(image_onnx)\n",
        "text_features = onnx_model.encode_text(text_onnx)\n",
        "\n",
        "logits_per_image, logits_per_text = onnx_model(image_onnx, text_onnx)\n",
        "probs = logits_per_image.softmax(dim=-1).detach().cpu().numpy()\n",
        "\n",
        "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421067 0.00299571]]"
      ],
      "metadata": {
        "id": "tYVuk72nSLw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install git+https://github.com/Lednik7/CLIP-ONNX.git"
      ],
      "metadata": {
        "id": "hiR47IE_1V3V",
        "outputId": "b0beab8a-5914-4a47-8dd4-e9c4d4464e0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Lednik7/CLIP-ONNX.git\n",
            "  Cloning https://github.com/Lednik7/CLIP-ONNX.git to /tmp/pip-req-build-gjmldtmk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Lednik7/CLIP-ONNX.git /tmp/pip-req-build-gjmldtmk\n",
            "  Resolved https://github.com/Lednik7/CLIP-ONNX.git to commit ebd4852b7d3ebf116709abf33b26832acaba947b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of clip-onnx to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.1 (from clip-onnx) (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117\n"
      ],
      "metadata": {
        "id": "70XLNzzr1eXt",
        "outputId": "7a581552-d4b4-4b70-ff64-ddf4a2b08f52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.1+cu117 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.1+cu117\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"ViT-L-14\"\n",
        "#print(open_clip.list_models())\n",
        "print(open_clip.list_pretrained(model_name))\n",
        "\n",
        "#pretrained = os.path.join(model_dir, f\"eva02_large_patch14_clip_224.merged2b_s4b_b131k/open_clip_pytorch_model.bin\")\n",
        "\n",
        "pretrained = \"/content/open_clip_pytorch_model.bin\"\n",
        "model, _, preprocess = open_clip.create_model_and_transforms(\n",
        "    model_name=model_name,\n",
        "    pretrained=pretrained,\n",
        ")\n",
        "# batch first\n",
        "image = preprocess(Image.open(\"CLIP.png\")).unsqueeze(0).cpu() # [1, 3, 224, 224]\n",
        "image_onnx = image.detach().cpu().numpy().astype(np.float32)"
      ],
      "metadata": {
        "id": "tVoVH4n22fvR",
        "outputId": "207a7709-0ad8-4b71-aacf-da10eee28c5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['RN50:openai', 'RN50:yfcc15m', 'RN50:cc12m', 'RN101:openai', 'RN101:yfcc15m', 'RN50x4:openai', 'RN50x16:openai', 'RN50x64:openai', 'ViT-B-32:openai', 'ViT-B-32:laion400m_e31', 'ViT-B-32:laion400m_e32', 'ViT-B-32:laion2b_e16', 'ViT-B-32:laion2b_s34b_b79k', 'ViT-B-32:datacomp_xl_s13b_b90k', 'ViT-B-32:datacomp_m_s128m_b4k', 'ViT-B-32:commonpool_m_clip_s128m_b4k', 'ViT-B-32:commonpool_m_laion_s128m_b4k', 'ViT-B-32:commonpool_m_image_s128m_b4k', 'ViT-B-32:commonpool_m_text_s128m_b4k', 'ViT-B-32:commonpool_m_basic_s128m_b4k', 'ViT-B-32:commonpool_m_s128m_b4k', 'ViT-B-32:datacomp_s_s13m_b4k', 'ViT-B-32:commonpool_s_clip_s13m_b4k', 'ViT-B-32:commonpool_s_laion_s13m_b4k', 'ViT-B-32:commonpool_s_image_s13m_b4k', 'ViT-B-32:commonpool_s_text_s13m_b4k', 'ViT-B-32:commonpool_s_basic_s13m_b4k', 'ViT-B-32:commonpool_s_s13m_b4k', 'ViT-B-32:metaclip_400m', 'ViT-B-32:metaclip_fullcc', 'ViT-B-32-256:datacomp_s34b_b86k', 'ViT-B-16:openai', 'ViT-B-16:laion400m_e31', 'ViT-B-16:laion400m_e32', 'ViT-B-16:laion2b_s34b_b88k', 'ViT-B-16:datacomp_xl_s13b_b90k', 'ViT-B-16:datacomp_l_s1b_b8k', 'ViT-B-16:commonpool_l_clip_s1b_b8k', 'ViT-B-16:commonpool_l_laion_s1b_b8k', 'ViT-B-16:commonpool_l_image_s1b_b8k', 'ViT-B-16:commonpool_l_text_s1b_b8k', 'ViT-B-16:commonpool_l_basic_s1b_b8k', 'ViT-B-16:commonpool_l_s1b_b8k', 'ViT-B-16:dfn2b', 'ViT-B-16:metaclip_400m', 'ViT-B-16:metaclip_fullcc', 'ViT-B-16-plus-240:laion400m_e31', 'ViT-B-16-plus-240:laion400m_e32', 'ViT-L-14:openai', 'ViT-L-14:laion400m_e31', 'ViT-L-14:laion400m_e32', 'ViT-L-14:laion2b_s32b_b82k', 'ViT-L-14:datacomp_xl_s13b_b90k', 'ViT-L-14:commonpool_xl_clip_s13b_b90k', 'ViT-L-14:commonpool_xl_laion_s13b_b90k', 'ViT-L-14:commonpool_xl_s13b_b90k', 'ViT-L-14:metaclip_400m', 'ViT-L-14:metaclip_fullcc', 'ViT-L-14:dfn2b', 'ViT-L-14:dfn2b_s39b', 'ViT-L-14-336:openai', 'ViT-H-14:laion2b_s32b_b79k', 'ViT-H-14:metaclip_fullcc', 'ViT-H-14:metaclip_altogether', 'ViT-H-14:dfn5b', 'ViT-H-14-378:dfn5b', 'ViT-g-14:laion2b_s12b_b42k', 'ViT-g-14:laion2b_s34b_b88k', 'ViT-bigG-14:laion2b_s39b_b160k', 'ViT-bigG-14:metaclip_fullcc', 'roberta-ViT-B-32:laion2b_s12b_b32k', 'xlm-roberta-base-ViT-B-32:laion5b_s13b_b90k', 'xlm-roberta-large-ViT-H-14:frozen_laion5b_s13b_b90k', 'convnext_base:laion400m_s13b_b51k', 'convnext_base_w:laion2b_s13b_b82k', 'convnext_base_w:laion2b_s13b_b82k_augreg', 'convnext_base_w:laion_aesthetic_s13b_b82k', 'convnext_base_w_320:laion_aesthetic_s13b_b82k', 'convnext_base_w_320:laion_aesthetic_s13b_b82k_augreg', 'convnext_large_d:laion2b_s26b_b102k_augreg', 'convnext_large_d_320:laion2b_s29b_b131k_ft', 'convnext_large_d_320:laion2b_s29b_b131k_ft_soup', 'convnext_xxlarge:laion2b_s34b_b82k_augreg', 'convnext_xxlarge:laion2b_s34b_b82k_augreg_rewind', 'convnext_xxlarge:laion2b_s34b_b82k_augreg_soup', 'coca_ViT-B-32:laion2b_s13b_b90k', 'coca_ViT-B-32:mscoco_finetuned_laion2b_s13b_b90k', 'coca_ViT-L-14:laion2b_s13b_b90k', 'coca_ViT-L-14:mscoco_finetuned_laion2b_s13b_b90k', 'EVA01-g-14:laion400m_s11b_b41k', 'EVA01-g-14-plus:merged2b_s11b_b114k', 'EVA02-B-16:merged2b_s8b_b131k', 'EVA02-L-14:merged2b_s4b_b131k', 'EVA02-L-14-336:merged2b_s6b_b61k', 'EVA02-E-14:laion2b_s4b_b115k', 'EVA02-E-14-plus:laion2b_s9b_b144k', 'ViT-B-16-SigLIP:webli', 'ViT-B-16-SigLIP-256:webli', 'ViT-B-16-SigLIP-i18n-256:webli', 'ViT-B-16-SigLIP-384:webli', 'ViT-B-16-SigLIP-512:webli', 'ViT-L-16-SigLIP-256:webli', 'ViT-L-16-SigLIP-384:webli', 'ViT-SO400M-14-SigLIP:webli', 'ViT-SO400M-16-SigLIP-i18n-256:webli', 'ViT-SO400M-14-SigLIP-378:webli', 'ViT-SO400M-14-SigLIP-384:webli', 'ViT-B-32-SigLIP2-256:webli', 'ViT-B-16-SigLIP2:webli', 'ViT-B-16-SigLIP2-256:webli', 'ViT-B-16-SigLIP2-384:webli', 'ViT-B-16-SigLIP2-512:webli', 'ViT-L-16-SigLIP2-256:webli', 'ViT-L-16-SigLIP2-384:webli', 'ViT-L-16-SigLIP2-512:webli', 'ViT-SO400M-14-SigLIP2:webli', 'ViT-SO400M-14-SigLIP2-378:webli', 'ViT-SO400M-16-SigLIP2-256:webli', 'ViT-SO400M-16-SigLIP2-384:webli', 'ViT-SO400M-16-SigLIP2-512:webli', 'ViT-gopt-16-SigLIP2-256:webli', 'ViT-gopt-16-SigLIP2-384:webli', 'ViT-L-14-CLIPA:datacomp1b', 'ViT-L-14-CLIPA-336:datacomp1b', 'ViT-H-14-CLIPA:datacomp1b', 'ViT-H-14-CLIPA-336:laion2b', 'ViT-H-14-CLIPA-336:datacomp1b', 'ViT-bigG-14-CLIPA:datacomp1b', 'ViT-bigG-14-CLIPA-336:datacomp1b', 'nllb-clip-base:v1', 'nllb-clip-large:v1', 'nllb-clip-base-siglip:v1', 'nllb-clip-base-siglip:mrl', 'nllb-clip-large-siglip:v1', 'nllb-clip-large-siglip:mrl', 'MobileCLIP-S1:datacompdr', 'MobileCLIP-S2:datacompdr', 'MobileCLIP-B:datacompdr', 'MobileCLIP-B:datacompdr_lt', 'MobileCLIP2-B:dfndr2b', 'MobileCLIP2-S0:dfndr2b', 'MobileCLIP2-S2:dfndr2b', 'MobileCLIP2-S3:dfndr2b', 'MobileCLIP2-S4:dfndr2b', 'MobileCLIP2-L-14:dfndr2b', 'ViTamin-S:datacomp1b', 'ViTamin-S-LTT:datacomp1b', 'ViTamin-B:datacomp1b', 'ViTamin-B-LTT:datacomp1b', 'ViTamin-L:datacomp1b', 'ViTamin-L-256:datacomp1b', 'ViTamin-L-336:datacomp1b', 'ViTamin-L-384:datacomp1b', 'ViTamin-L2:datacomp1b', 'ViTamin-L2-256:datacomp1b', 'ViTamin-L2-336:datacomp1b', 'ViTamin-L2-384:datacomp1b', 'ViTamin-XL-256:datacomp1b', 'ViTamin-XL-336:datacomp1b', 'ViTamin-XL-384:datacomp1b', 'PE-Core-T-16-384:meta', 'PE-Core-S-16-384:meta', 'PE-Core-B-16:meta', 'PE-Core-L-14-336:meta', 'PE-Core-bigG-14-448:meta', 'ViT-H-14-worldwide:metaclip2_worldwide', 'ViT-H-14-worldwide-378:metaclip2_worldwide', 'ViT-bigG-14-worldwide:metaclip2_worldwide', 'ViT-bigG-14-worldwide-378:metaclip2_worldwide', 'RN50-quickgelu:openai', 'RN50-quickgelu:yfcc15m', 'RN50-quickgelu:cc12m', 'RN101-quickgelu:openai', 'RN101-quickgelu:yfcc15m', 'RN50x4-quickgelu:openai', 'RN50x16-quickgelu:openai', 'RN50x64-quickgelu:openai', 'ViT-B-32-quickgelu:openai', 'ViT-B-32-quickgelu:laion400m_e31', 'ViT-B-32-quickgelu:laion400m_e32', 'ViT-B-32-quickgelu:metaclip_400m', 'ViT-B-32-quickgelu:metaclip_fullcc', 'ViT-B-16-quickgelu:openai', 'ViT-B-16-quickgelu:dfn2b', 'ViT-B-16-quickgelu:metaclip_400m', 'ViT-B-16-quickgelu:metaclip_fullcc', 'ViT-L-14-quickgelu:openai', 'ViT-L-14-quickgelu:metaclip_400m', 'ViT-L-14-quickgelu:metaclip_fullcc', 'ViT-L-14-quickgelu:dfn2b', 'ViT-L-14-336-quickgelu:openai', 'ViT-H-14-quickgelu:metaclip_fullcc', 'ViT-H-14-quickgelu:dfn5b', 'ViT-H-14-378-quickgelu:dfn5b', 'ViT-bigG-14-quickgelu:metaclip_fullcc', 'ViT-H-14-worldwide-quickgelu:metaclip2_worldwide']\n"
          ]
        }
      ]
    }
  ]
}